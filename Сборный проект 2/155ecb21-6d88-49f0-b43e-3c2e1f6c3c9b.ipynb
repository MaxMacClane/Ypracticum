{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Цель:\" data-toc-modified-id=\"Цель:-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Цель:</a></span></li><li><span><a href=\"#Технологический-процесс\" data-toc-modified-id=\"Технологический-процесс-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Технологический процесс</a></span></li><li><span><a href=\"#Описание-данных\" data-toc-modified-id=\"Описание-данных-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Описание данных</a></span></li><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Проверка-расчёта-эффективности-обогащения\" data-toc-modified-id=\"Проверка-расчёта-эффективности-обогащения-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Проверка расчёта эффективности обогащения</a></span></li><li><span><a href=\"#Анализ-данных\" data-toc-modified-id=\"Анализ-данных-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Анализ данных</a></span></li><li><span><a href=\"#Модель\" data-toc-modified-id=\"Модель-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Модель</a></span></li><li><span><a href=\"#Чек-лист-готовности-проекта\" data-toc-modified-id=\"Чек-лист-готовности-проекта-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Чек-лист готовности проекта</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Восстановление золота из руды\n",
    "Сборный проект 2\n",
    "Выполнил Максим Ларин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цель:\n",
    "\n",
    "Подготовить прототип модели машинного обучения для «Цифры». Компания разрабатывает решения для эффективной\n",
    "работы промышленных предприятий.\n",
    "\n",
    "Модель должна предсказать коэффициент восстановления золота из золотосодержащей руды используя данные с\n",
    "параметрами добычи и очистки.\n",
    "\n",
    "Модель поможет оптимизировать производство, чтобы не запускать предприятие с убыточными характеристиками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Технологический процесс\n",
    "\n",
    "<img src=\"https://pictures.s3.yandex.net/resources/viruchka_1576238830.jpg\" width=\"600\" height=\"300\">\n",
    "\n",
    "<br><a name=\"d\">Расчёт эффективности</a><br>\n",
    "<img src='https://pictures.s3.yandex.net/resources/Recovery_1576238822.jpg' width=\"600\" height=\"150\">\n",
    "\n",
    "C — доля золота в концентрате после флотации/очистки;<br>\n",
    "F — доля золота в сырье/концентрате до флотации/очистки;<br>\n",
    "T — доля золота в отвальных хвостах после флотации/очистки.<br>\n",
    "\n",
    "<br>Метрика качества<br>\n",
    "<img src='https://pictures.s3.yandex.net/resources/smape_1576239058.jpg' width=\"600\" height=\"200\">\n",
    "\n",
    "sMAPE (англ. Symmetric Mean Absolute Percentage Error, «симметричное среднее абсолютное процентное отклонение»)<br>\n",
    "Одинаково учитывает масштаб и целевого признака, и предсказания.<br>\n",
    "<br>\n",
    "<img src='https://pictures.s3.yandex.net/resources/_smape_1576239054.jpg' width=\"600\" height=\"200\">\n",
    "\n",
    "Нужно спрогнозировать сразу две величины:<br>\n",
    "эффективность обогащения чернового концентрата rougher.output.recovery;<br>\n",
    "эффективность обогащения финального концентрата final.output.recovery.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных\n",
    "***Технологический процесс***\n",
    "\n",
    "- Rougher feed — исходное сырье\n",
    "- Rougher additions (или reagent additions) — флотационные реагенты: Xanthate, Sulphate, Depressant\n",
    "    > Xanthate **— ксантогенат (промотер, или активатор флотации);<br>\n",
    "    >  Sulphate — сульфат (на данном производстве сульфид натрия);<br>\n",
    "    > Depressant — депрессант (силикат натрия).\n",
    "- Rougher process (англ. «грубый процесс») — флотация\n",
    "- Rougher tails — отвальные хвосты\n",
    "- Float banks — флотационная установка\n",
    "- Cleaner process — очистка\n",
    "- Rougher Au — черновой концентрат золота\n",
    "- Final Au — финальный концентрат золота\n",
    "\n",
    "***Параметры этапов***\n",
    "- air amount — объём воздуха\n",
    "- fluid levels — уровень жидкости\n",
    "- feed size — размер гранул сырья\n",
    "- feed rate — скорость подачи\n",
    "\n",
    "***Наименование признаков***\n",
    "Наименование признаков должно быть такое:<br>\n",
    " > `[этап].[тип_параметра].[название_параметра]`<br>\n",
    " > ``Пример: rougher.input.feed_ag``<br>\n",
    " > ```Возможные значения для блока [этап]:```<br>\n",
    "- rougher — флотация\n",
    "- primary_cleaner — первичная очистка\n",
    "- secondary_cleaner — вторичная очистка\n",
    "- final — финальные характеристики\n",
    "- Возможные значения для блока [тип_параметра]:\n",
    "- input — параметры сырья\n",
    "- output — параметры продукта\n",
    "- state — параметры, характеризующие текущее состояние этапа\n",
    "- calculation — расчётные характеристики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. Проверьте, что эффективность обогащения рассчитана правильно. Вычислите её на обучающей выборке для признака rougher.output.recovery. Найдите MAE между вашими расчётами и значением признака. Опишите выводы.\n",
    "1.3. Проанализируйте признаки, недоступные в тестовой выборке. Что это за параметры? К какому типу относятся?\n",
    "1.4. Проведите предобработку данных.\n",
    "2. Проанализируйте данные\n",
    "2.1. Посмотрите, как меняется концентрация металлов (Au, Ag, Pb) на различных этапах очистки. Опишите выводы.\n",
    "2.2.  Сравните распределения размеров гранул сырья на обучающей и тестовой выборках. Если распределения сильно отличаются друг от друга, оценка модели будет неправильной.\n",
    "2.3. Исследуйте суммарную концентрацию всех веществ на разных стадиях: в сырье, в черновом и финальном концентратах.\n",
    "3. Постройте модель\n",
    "3.1. Напишите функцию для вычисления итоговой sMAPE.\n",
    "3.2. Обучите разные модели и оцените их качество кросс-валидацией. Выберите лучшую модель и проверьте её на тестовой выборке. Опишите выводы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "from scipy import stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as ex\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_train = pd.read_csv('gold_recovery_train_new.csv', index_col='date')\n",
    "    data_test = pd.read_csv('gold_recovery_test_new.csv', index_col='date')\n",
    "    data_full = pd.read_csv('gold_recovery_full_new.csv', index_col='date')\n",
    "except:\n",
    "    data_train = pd.read_csv('https://code.s3.yandex.net/datasets/gold_recovery_train_new.csv', index_col='date')\n",
    "    data_test = pd.read_csv('https://code.s3.yandex.net/datasets/gold_recovery_test_new.csv', index_col='date')\n",
    "    data_full = pd.read_csv('https://code.s3.yandex.net/datasets/gold_recovery_full_new.csv', index_col='date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('data_test')\n",
    "display(data_test.info())\n",
    "print()\n",
    "print('data_train')\n",
    "display(data_train.info())\n",
    "print()\n",
    "print('data_full')\n",
    "display(data_full.info())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в data_test на 34 столбца меньше чем в остальных <br>\n",
    "Во всех столбцах тип данных числовой и есть пропуски <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# посмотрим на данные\n",
    "display(f'data_test', data_test.head(5))\n",
    "display(f'data_train', data_train.head(5))\n",
    "display(f'data_full', data_full.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Проверим названия столбзов данных trein и full равны или нет\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# проверим названия столбзов данных trein и full равны или нет\n",
    "if np.array_equal(data_full.columns, data_train.columns):\n",
    "    print('Названия столбцов data_full и data_trein совпадают')\n",
    "# проверим на дубликаты\n",
    "for i, ii in zip([data_test, data_train, data_full], ['data_test', 'data_train', 'data_full']):\n",
    "    s = i.duplicated().sum()\n",
    "    print(f'Количество дубликатов в данных {ii} равно {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('data_test', data_test.describe(include='all'))\n",
    "display('data_train', data_train.describe(include='all'))\n",
    "display('data_full', data_full.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видим, что train и full выборки равны по количеству и названию столбцов<br>\n",
    "В data_full data_train есть пропуски<br>\n",
    "Test и train выборки отличаются по количеству признаков, что является препятствием, для проверки модели<br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Проверка расчёта эффективности обогащения\n",
    "Проверим правильно ли посчитана rougher.output.recovery <br>\n",
    "Эффективность расчитывается по этой формуле <br>\n",
    "\n",
    "<img src='https://pictures.s3.yandex.net/resources/Recovery_1576238822.jpg' width=\"600\" height=\"150\">\n",
    "\n",
    "C — доля золота в концентрате после флотации/очистки;<br>\n",
    "F — доля золота в сырье/концентрате до флотации/очистки;<br>\n",
    "T — доля золота в отвальных хвостах после флотации/очистки.<br>\n",
    "<br>\n",
    "<img src='https://pictures.s3.yandex.net/resources/smape_1576239058.jpg' width=\"600\" height=\"150\">\n",
    "<br>\n",
    "<img src='https://pictures.s3.yandex.net/resources/_smape_1576239054.jpg' width=\"600\" height=\"150\">\n",
    "\n",
    "Напишем функцию которая из переданных данных вернёт SMAPE и MAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def efficiency_calculation(data_recov, C, F, T):\n",
    "    # данные для расчета эфективности обогощения\n",
    "    past_recovery = data_recov[data_recov.notnull()]\n",
    "    C = C[C.notnull()]\n",
    "    F = F[F.notnull()]\n",
    "    T = T[T.notnull()]\n",
    "    new_recovery = C*(F - T)/(F*(C - T))*100\n",
    "    # расчет sMAPE и MAE\n",
    "    numerator = abs(past_recovery - new_recovery)\n",
    "    denominator = (abs(past_recovery) + abs(new_recovery))*0.5\n",
    "    N = len(past_recovery)\n",
    "    SMAPE = 1/N*(numerator/denominator).sum()*100\n",
    "    MAE =  1/N*(numerator).sum()\n",
    "    return SMAPE, MAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# воспользуемся формулой для расчета SMAPE и MAE признака rougher.output.recovery\n",
    "SMAPE_rougher, MAE_rougher = (\n",
    "    efficiency_calculation(data_recov=data_train['rougher.output.recovery'],\n",
    "                           C=data_train['rougher.output.concentrate_au'],\n",
    "                           F=data_train['rougher.input.feed_au'],\n",
    "                           T=data_train['rougher.output.tail_au']))\n",
    "\n",
    "print(f'Симметричная средняя абсолютная ошибка в процентах {sMAPE_rougher:.2E}')\n",
    "print(f'Средняя абсолютная ошибка  {MAE_rougher:.2E}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Вывод\n",
    "Значение SMAPE и  MAE очень, очень маленькие, что свидетельствует о правильном расчете <br>\n",
    "Показателя для признака `rougher.output.recovery`\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Признаки отсутствующие в data_test данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gone_columns = list(set(data_train.columns) - set(data_test.columns))\n",
    "gone_columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видим по названиям отсутствующих столбцов в test данных, что это параметры output или calculation<br>\n",
    "Можно предположить, что из-за того, что параметры несут в себе результаты обработки, расчетов и могут иметь<br>\n",
    "Высокую корреляцию с целевым признаком их исключили из набора данных<br>\n",
    "В дальнейшем приведём train к виду test по столбцам и продолжим работать<br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# проверим корреляцию отсутствующих столбцов c  final.output.recovery и rougher.output.recovery\n",
    "exam_corr = data_train.loc[:][gone_columns]\n",
    "corr = exam_corr.corr()\n",
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "ax = sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap='coolwarm', annot=True);\n",
    "ax.set_title('проверяем корреляцию отсутствующих столбцов test и целевого признака ',\n",
    "             dict(fontweight='bold', fontsize=14));\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Вывод\n",
    "Отсутствующие признаки в test данных это параметры output или calculation<br>\n",
    "Возможность их интерпритации наступает после флотации и очистки <br>\n",
    "У целевого признака rougher.output.recovery наблюдается корреляция средней силы с признаками<br>\n",
    "rougher.output.concentrate_pb, rougher.output.concentrate_au, rougher.output.concentrate_ag,<br>\n",
    "rougher.output.concentrate_sol\n",
    "Признак final.output.recovery имеет слабую корреляцию <br>\n",
    "\n",
    "Все отсутствующие признаки имеют характеристики целевых признаков и корреляцию средней силы с целевым признаком<br>\n",
    "Поэтим причинам отсутствующие признаки не подходят для обучения модели<br>\n",
    "\n",
    "Примем это за факт уберём из train лишние столбцы и будем работать как есть<br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Проверим пропуски"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# сравним данные в trein и full\n",
    "data_train.describe(include='all').isin(\n",
    "    data_full.loc[data_train.index].describe(include='all')).value_counts().to_frame()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# посмотрим на признаки с различиями\n",
    "exam1 = data_full.loc[data_train.index]['primary_cleaner.state.floatbank8_a_air'].describe() == data_train[\n",
    "    'primary_cleaner.state.floatbank8_a_air'].describe()\n",
    "exam2 = data_full.loc[data_train.index]['secondary_cleaner.state.floatbank2_b_air'].describe() == data_train[\n",
    "    'secondary_cleaner.state.floatbank2_b_air'].describe()\n",
    "exam3 = data_full.loc[data_train.index]['secondary_cleaner.state.floatbank2_b_level'].describe() == data_train[\n",
    "    'secondary_cleaner.state.floatbank2_b_level'].describe()\n",
    "exam4 = data_full.loc[data_train.index]['secondary_cleaner.state.floatbank5_a_air'].describe() == data_train[\n",
    "    'secondary_cleaner.state.floatbank5_a_air'].describe()\n",
    "exam_equal = pd.concat([exam1, exam2, exam3, exam4], axis=1)\n",
    "display(exam_equal)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# сравним суммы столбцов с различиями в описании\n",
    "exam1 = data_full.loc[data_train.index]['primary_cleaner.state.floatbank8_a_air'].sum() == data_train[\n",
    "    'primary_cleaner.state.floatbank8_a_air'].sum()\n",
    "exam2 = data_full.loc[data_train.index]['secondary_cleaner.state.floatbank2_b_air'].sum() == data_train[\n",
    "    'secondary_cleaner.state.floatbank2_b_air'].sum()\n",
    "exam3 = data_full.loc[data_train.index]['secondary_cleaner.state.floatbank2_b_level'].sum() == data_train[\n",
    "    'secondary_cleaner.state.floatbank2_b_level'].sum()\n",
    "exam4 = data_full.loc[data_train.index]['secondary_cleaner.state.floatbank5_a_air'].sum() == data_train[\n",
    "    'secondary_cleaner.state.floatbank5_a_air'].sum()\n",
    "\n",
    "if exam1 == exam2 == exam3 == exam4:\n",
    "    print(f'Суммы в столбцах в которых наблюдались различия равны.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видим, что данные в train и full полностью совпадают<br>\n",
    "Различия в столбцах\n",
    "primary_cleaner.state.floatbank8_a_air\n",
    "secondary_cleaner.state.floatbank2_b_air\n",
    "secondary_cleaner.state.floatbank2_b_level\n",
    "secondary_cleaner.state.floatbank5_a_air\n",
    "Не значительные, можем предположить, что получились в результате округления<br>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# сравним данные в test и full\n",
    "data_test.describe(include='all').isin(data_full.loc[data_test.index].describe(include='all')).value_counts().to_frame()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Данные data_full и data_test равны\n",
    "Убедились, что данные train и test принадлежат data_frame full"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# разложим названия признаком по группам\n",
    "split = pd.DataFrame([*data_full.columns.str.split(\".\")], columns=['stage', 'parameter_type', 'parameter_name'])\n",
    "\n",
    "# посмотрим сколько всего уникальных этапов, состояний и параметров\n",
    "stage = pd.Series(split['stage'])\n",
    "parameter_type = pd.Series(split['parameter_type'])\n",
    "parameter_name = pd.Series(split['parameter_name'])           #.unique()\n",
    "parameter_columns_name = pd.concat([stage, parameter_type, parameter_name], axis=1)\n",
    "# parameter_columns_name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# проверим пропуски и создадим графическое изображение для сравнения\n",
    "exam_full = data_full.isna().sum() > 0\n",
    "exam_full = pd.DataFrame(data_full.isna().sum()[exam_full]).T\n",
    "\n",
    "exam_train = data_train.isna().sum() > 0\n",
    "exam_train = pd.DataFrame(data_train.isna().sum()[exam_train]).T\n",
    "\n",
    "exam_test = data_test.isna().sum() > 0\n",
    "exam_test = pd.DataFrame(data_test.isna().sum()[exam_test]).T\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(25, 12));\n",
    "plt.subplots_adjust(wspace=0.8, hspace=0.5)\n",
    "full = (sns.barplot(exam_full, orient='h', ax=ax1).set_title(\n",
    "    'пропуски в data_full свего {} шт., в {} столбцах'.format(exam_full.values.sum(), len(exam_full.T)),\n",
    "    dict(fontweight='bold', fontsize=14)));\n",
    "axes = full.axes.set(xlim=(0, 50));\n",
    "\n",
    "train = (sns.barplot(exam_train, orient='h', ax=ax2).set_title(\n",
    "    'пропуски в data_train свего {} шт., в {} столбцах'.format(exam_train.values.sum(), len(exam_train.T)),\n",
    "    dict(fontweight='bold', fontsize=14)));\n",
    "axes = train.axes.set(xlim=(0, 50));\n",
    "\n",
    "test = (sns.barplot(exam_test, orient='h', ax=ax3).set_title(\n",
    "    'пропуски в data_test свего {} шт., в {} столбцах'.format(exam_test.values.sum(), len(exam_test.T)),\n",
    "    dict(fontweight='bold', fontsize=14)));\n",
    "axes = test.axes.set(xlim=(0, 50));\n",
    "\n",
    "plt.xticks(rotation=90);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Посмотрели на пропуски, везде есть <br>\n",
    "В описании сказано, что значения признаков расположенных рядом близки <br>\n",
    "Заполним пропуски в data_full значениями расположенными рядом <br>\n",
    "Затем поделим на train и test выборку соблюдая пропорции которые есть <br>\n",
    "И наминал столбцов test выборки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# проверим наличие пропусков в последней строке\n",
    "isna_last_row = data_full[data_full.columns][-1:].values\n",
    "if np.isnan(isna_last_row[0]).sum() > 0:\n",
    "    print('В последней строчке есть пропуски и надо их заполнить в первую очередь')\n",
    "else:\n",
    "    print('В последней строчке нет пропусков, можно реализовывать заполнение подстановкой близко стоящим значением')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "isna_data_full = data_full.copy()\n",
    "isna_data_full = isna_data_full.fillna(method='bfill', axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# проверим заполнение\n",
    "display(isna_data_full.describe())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SMAPE_final, MAE_final = (\n",
    "    efficiency_calculation(data_recov=data_train['final.output.recovery'], C=data_train['final.output.concentrate_au'],\n",
    "                           F=data_train['primary_cleaner.output.concentrate_au'], T=data_train['final.output.tail_au']))\n",
    "\n",
    "print(f'{SMAPE_final:.2F}')\n",
    "print(f'{MAE_final.sum()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "parameter_columns_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке выполнения\n",
    "- [ ]  Выполнен шаг 1: данные подготовлены\n",
    "    - [ ]  Проверена формула вычисления эффективности обогащения\n",
    "    - [ ]  Проанализированы признаки, недоступные в тестовой выборке\n",
    "    - [ ]  Проведена предобработка данных\n",
    "- [ ]  Выполнен шаг 2: данные проанализированы\n",
    "    - [ ]  Исследовано изменение концентрации элементов на каждом этапе\n",
    "    - [ ]  Проанализированы распределения размеров гранул на обучающей и тестовой выборках\n",
    "    - [ ]  Исследованы суммарные концентрации\n",
    "- [ ]  Выполнен шаг 3: построена модель прогнозирования\n",
    "    - [ ]  Написана функция для вычисления итогового *sMAPE*\n",
    "    - [ ]  Обучено и проверено несколько моделей\n",
    "    - [ ]  Выбрана лучшая модель, её качество проверено на тестовой выборке"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
